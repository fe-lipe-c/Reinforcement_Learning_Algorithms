{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 5\n",
    "## Deep Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import atari_wrappers as atari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_name, fire=True, frames_num=2, noop_num=30, skip_frames=True):\n",
    "    \n",
    "    env = gym.make(env_name)\n",
    "    \n",
    "    if skip_frames:\n",
    "        env = atari.MaxAndSkipEnv(env) ## Return only every skip-th frame\n",
    "        \n",
    "    if fire:\n",
    "        env = atari.FireResetEnv(env) ## Fire at the beggining\n",
    "        \n",
    "    env = atari.NoopResetEnv(env,noop_max=noop_num)\n",
    "    env = atari.WarpFrame(env) ## Reshape image\n",
    "    env = atari.FrameStack(env, frames_num) ## Stack last 2 frames\n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(Model):\n",
    "    \n",
    "    def __init__(self, h_layers, h_size, o_size, h_activation=tf.nn.relu, o_activation=None):\n",
    "        \n",
    "        super(QNet,self).__init__()\n",
    "        self.conv_layer1 = Conv2D(filters=16, kernel_size=8, strides=4, padding='valid', activation='relu')\n",
    "        self.conv_layer2 = Conv2D(filters=32, kernel_size=4, strides=2, padding='valid', activation='relu')\n",
    "        self.conv_layer3 = Conv2D(filters=32, kernel_size=3, strides=1, padding='valid', activation='relu')\n",
    "        \n",
    "        self.flatten_layer = Flatten()\n",
    "        \n",
    "        self.hidden_layers = [Dense(h_size[i], activation=h_activation) for i in range(h_layers)]\n",
    "        self.output_layer = Dense(o_size, activation=o_activation)\n",
    "        \n",
    "    def call(self,input_data):\n",
    "        \n",
    "        x = input_data\n",
    "        \n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.conv_layer3(x)\n",
    "        \n",
    "        x = self.flatten_layer(x)\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            \n",
    "            x = layer(x)\n",
    "            \n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_frames(frames):\n",
    "    \n",
    "    return np.array(frames, dtype=np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceBuffer():\n",
    "    \n",
    "    def __init__(self,buffer_size):\n",
    "        \n",
    "        self.obs_buf = deque(maxlen=buffer_size)\n",
    "        self.rew_buf = deque(maxlen=buffer_size)\n",
    "        self.act_buf = deque(maxlen=buffer_size)\n",
    "        self.next_obs_buf = deque(maxlen=buffer_size)\n",
    "        self.done_buf = deque(maxlen=buffer_size)\n",
    "        \n",
    "    def add(self, obs, rew, act, next_obs, done):\n",
    "        \n",
    "        self.obs_buf.append(obs)\n",
    "        self.rew_buf.append(rew)\n",
    "        self.act_buf.append(act)\n",
    "        self.next_obs_buf.append(obs2)\n",
    "        self.done_buf.append(done)\n",
    "        \n",
    "    def samble_minibatch(self, batch_size):\n",
    "        \n",
    "        mb_indices = np.random.randint(len(self.obs_buf),size=batch_size)\n",
    "        \n",
    "        mb_obs = scale_frames([self.obs_buf[i] for i in mb_indices])\n",
    "        mb_rew = [self.rew_buf[i] for i in mb_indices] \n",
    "        mb_act = [self.act_buf[i] for i in mb_indices]\n",
    "        mb_next_obs = scale_frames([self.next_obs_buf[i] for i in mb_indices])\n",
    "        mb_done = [self.done_buf[i] for i in mb_indices]\n",
    "    \n",
    "        return mb_obs, mb_rew, mb_act, mb_next_obs, mb_done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.obs_buf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(target_qv,online_qv):\n",
    "    \n",
    "    target_qv.set_weights(online_qv.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_greedy(action_values,epsilon=0.1):\n",
    "    \n",
    "    if np.random.uniform(0,1) < epsilon:\n",
    "        \n",
    "        return np.random.randint(len(action_values))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return np.argmax(action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(env_name, hidden_layers =1, hidden_size=[32], alpha=1e-2, num_epochs=2000, buffer_size=100000, gamma=0.99,\n",
    "        update_target_net=1000, batch_size=64, update_freq=4, frames_num=2, min_buffer_size=5000, test_frequency=20,\n",
    "        start_exp=1, end_exp=0.1, exp_steps=100000):\n",
    "    \n",
    "    env = make_env(env_name, frames_num=frames_num, skip_frames=True, noop_num=20)\n",
    "    env_test = make_env(env_name,frames_num=frames_num, skip_frames=True, noop_num=20)\n",
    "    \n",
    "    env_test = gym.wrappers.Monitor(env_test, \"VIDEOS/TEST_VIDEOS\"+env_name+str(current_milli_time()), force=True,\n",
    "                                    video_callable=lambda x: x%20==0)\n",
    "    \n",
    "    obs_dim = env.observation_space.shape\n",
    "    act_dim = env.action_space.n\n",
    "    \n",
    "    target_qv = QNet(h_layers=hidden_layers, h_size=hidden_size, o_size=act_dim)\n",
    "    online_qv = QNet(h_layers=hidden_layers, h_size=hidden_size, o_size=act_dim)\n",
    "    \n",
    "    obs = env.reset()\n",
    "    obs = scale_frames(obs)\n",
    "    \n",
    "    _ = target_qv.predict(np.array([obs]))\n",
    "    _ = online_qv.predict(np.array([obs]))\n",
    "    \n",
    "    update_target(target_qv,online_qv)\n",
    "    \n",
    "    #####################\n",
    "    ### TENSORBOARD ##### --> Not implemented\n",
    "    #####################\n",
    "    \n",
    "    step_count = 0\n",
    "    last_update_loss = []\n",
    "    ep_time = current_milli_time()\n",
    "    batch_rew = []\n",
    "    \n",
    "    buffer = ExperienceBuffer(buffer_size)\n",
    "    epsilon = start_exp\n",
    "    eps_decay = (start_exp - end_exp)/exp_steps\n",
    "    \n",
    "    obs = env.reset()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        game_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            \n",
    "            obs_process = np.array([scale_frames(obs)])\n",
    "            action_values = online_qv.predict(obs_process)[0]\n",
    "            \n",
    "            action = e_greedy(action_values, epsilon)\n",
    "            next_obs, reward, done, _ = env.step(action) \n",
    "            buffer.add(obs, reward, action, next_obs, done)\n",
    "            \n",
    "            obs = next_obs\n",
    "            game_reward += reward\n",
    "            step_count += 1\n",
    "            \n",
    "            if epsilon > end_exp:\n",
    "                epsilon -= eps_decay\n",
    "                \n",
    "            if len(buffer) > min_buffer_size and (step_count % update_freq == 0):\n",
    "                \n",
    "                mb_obs, mb_rew, mb_act, mb_next_obs, mb_done = buffer.sample_minibatch(batch_size)\n",
    "                \n",
    "                \n",
    "                #mb_target_act = target_qv.predict\n",
    "            \n",
    "            done=True\n",
    "            \n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8bc0a3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8bc1472f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "t = DQN('PongNoFrameskip-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17649953, -0.05435145,  0.08430061, -0.03263599,  0.11034723,\n",
       "        -0.02487457]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spinningup)",
   "language": "python",
   "name": "spinningup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
